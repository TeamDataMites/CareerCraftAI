from typing import List, Sequence 
from langgraph.graph import MessageGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage

from utils.chat.mindmap.prompt import SYSTEM_PROMPT
import dotenv
import os

dotenv.load_dotenv()
os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')



class Reflection:
    def __init__(self):
        self.search = TavilySearchResults(max_results=5)
        self.llm = ChatOpenAI(model='gpt-4o')
        self.llmy = ChatOpenAI(model='gpt-4-turbo-2024-04-09')

    def mentor_agent(self, desc: str = None):

        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    SYSTEM_PROMPT,
                ),
                MessagesPlaceholder(variable_name="messages"),
            ]
        )

        generate = prompt.partial(desc=desc) | self.llm

        return generate

    def reflection(self):
        reflection_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "You are an Industry leading Tech Recruiter. Generate critique and recommendations for the roadmap generated by the job description."
                    "Research the web and provide detailed recommendations, including correct sub topics to learn, job appropriate facts and advice"
                    "Focus more on topics that will be questioned in an interview."
                ),
                MessagesPlaceholder(variable_name="messages"),
            ]
        )
        reflect = reflection_prompt | self.llm

        return reflect


reflection = Reflection()

def generation_node(state: Sequence[BaseMessage]) -> List[BaseMessage]:
    if len(state) == 1:
        return reflection.mentor_agent(desc=state[0].content).invoke({
                "messages": [HumanMessage(content="Make sure that the road map you created suites the job description & that it contains all the skills necessary for the job.")]
            })
    return reflection.mentor_agent(desc=state[0]).invoke({"messages": state})
    

def reflection_node(state: Sequence[BaseMessage]) -> List[BaseMessage]:

    cls_map = {
        "ai": HumanMessage,
        "human": AIMessage,
    }

    translated = [state[0]] + [
        cls_map[msg.type](content=msg.content) for msg in state[1:]
    ]

    res = reflection.reflection().invoke({"messages": translated})

    return HumanMessage(content=res.content)


builder = MessageGraph()

builder.add_node("generate", generation_node)
builder.add_node("reflect", reflection_node)
builder.set_entry_point("generate")

def should_continue(state: List[BaseMessage]):
    if len(state) > 5:
        # End after 5 iterations
        return END
    return "reflect"

builder.add_conditional_edges("generate", should_continue)
builder.add_edge("reflect", "generate")
graph = builder.compile()


def mindmap_agent(message: str):
    msg = HumanMessage(content=message)
    answer = graph.invoke([msg])
    return answer[-1].content